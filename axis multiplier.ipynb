{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import allocate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/pynq/overlays/multiplier/axis_multiplier.bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynq.lib.dma\n",
    "\n",
    "dma = overlay.axi_dma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class copied from the original script. You can easily import it as module without copying the code.\n",
    "from fxpmath import Fxp\n",
    "import numpy as np\n",
    "\n",
    "class Converter():\n",
    "\n",
    "    def forward_conversion(self, input_data, signed, total_bits, fractional_bits):\n",
    "        '''\n",
    "        Converts input data from float/int python data types to ap_fixed with total bits and fractional_bits and returns its uint32 equivalent\n",
    "        :param input_data: can be both a single int/float number or a numpy array\n",
    "        :param signed: Boolean, if the input data is signed or not\n",
    "        :param total_bits: numer of total bits used to represent the input data\n",
    "        :param fractional_bits: number of fractional bits used to represent the input data. Integer bits = total bits - fractional bits\n",
    "        :return: input data converted to uint32 format. 0.5 can be represented with 4 bits as 0.100. This is converted into 0100 (fractional point removed) and then converted to int.\n",
    "                 0.5 as input is converted to 4 as uint32.\n",
    "        '''\n",
    "        fixed_point_representation = Fxp(input_data, signed=signed, n_word = total_bits, n_frac = fractional_bits)\n",
    "        uint_coverted = np.uint32(fixed_point_representation.uraw())\n",
    "        return uint_coverted\n",
    "\n",
    "\n",
    "\n",
    "    def backward_conversion(self, input_data, total_bits, fractional_bits):\n",
    "        '''\n",
    "        Converts input data from uint32 format to float with total_bits and fractional_bits resolution\n",
    "        :param input_data: can be both a single int/float number or a numpy array\n",
    "        :param total_bits: numer of total bits used to represent the input data\n",
    "        :param fractional_bits: number of fractional bits used to represent the input data. Integer bits = total bits - fractional bits\n",
    "        :return: converted input data from uint32 to float\n",
    "        '''\n",
    "\n",
    "        if type(input_data) is not np.ndarray:\n",
    "            input_data = np.array([input_data])\n",
    "\n",
    "        #Function taken from here: https://discuss.pynq.io/t/how-to-use-ap-fixed-data-type-to-communicate-with-the-ip-made-by-the-vivado-hls/679/5\n",
    "        condition = 1 << (total_bits - 1)\n",
    "        mask = (~((1 << total_bits) - 1)) & 0xFFFFFFFF\n",
    "        return np.where(input_data < condition, input_data, (input_data.view('u4') | mask).view('i4')) / (1 << fractional_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/fxpmath/objects.py:579: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  if original_vdtype != complex and not np.issubdtype(original_vdtype, complex):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  4194304,   1048576, 266338304], dtype=uint32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = np.array([1,0.25,-0.5])\n",
    "converter = Converter()\n",
    "#NB: in the total_bits-Fractional_bits declaration, remembr to match the actual data size of your hardware ip!\n",
    "input_data_forward_conversion = converter.forward_conversion(input_data=input_data, signed=True, total_bits = 28, fractional_bits=22)\n",
    "input_data_forward_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PynqBuffer([3145728], dtype=uint32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynq import allocate\n",
    "import numpy as np\n",
    "\n",
    "# IGNORE THIS COMMENT\n",
    "#IMPORTANTE: con l'output nel design a ap_fixed<32> funziona correttamente. Con delle dimensioni inferiori, spara valori a caso.\n",
    "# molto probabilmente è un problema di alignment e/o estensione dei bit. Ad esempio con l'output a 24 bit, l'adapter deve estendere\n",
    "# a 32 bit per la DMA, forse è qui il problema.\n",
    "\n",
    "# Dalla documentazione (https://www.xilinx.com/support/documentation/ip_documentation/axis_infrastructure_ip_suite/v1_1/pg085-axi4stream-infrastructure.pdf)\n",
    "# il data width converter se scrivo da più piccolo a più grande, mi mette assieme più chunk e poi scrive tutto assieme,\n",
    "# viceversa mette in serie (è scritto nelle prime righe dela documentazione)\n",
    "# Quindi con l'output non multiplo di 32 (ad esempio 24), si spacca tutto. In teoria il problema è che l'IP scrive come risultato\n",
    "# 24 bit, tuttavia l'input della DMA e il data converter è a 32 bit, quindi mi concatena 8 bit del risultato successivo ai 24 del precedente\n",
    "# e quindi mi vengono risultati a caso\n",
    "\n",
    "in_buffer = allocate(shape=(3,), dtype=np.uint32)\n",
    "out_buffer = allocate(shape=(1,), dtype=np.uint32)\n",
    "\n",
    "# The following assignment makes the kernel die, don't know why\n",
    "#in_buffer[:] = input_data_forward_conversion[:]\n",
    "\n",
    "#The following one works fine\n",
    "for i in range(3):\n",
    "    in_buffer[i] = input_data_forward_conversion[i]\n",
    "    \n",
    "\n",
    "\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "\n",
    "dma.sendchannel.wait()\n",
    "dma.recvchannel.wait()\n",
    "\n",
    "out_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = converter.backward_conversion(out_buffer, 28, 22)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
